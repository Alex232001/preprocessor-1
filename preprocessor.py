import numpy as np
import librosa
import json
from pydub import AudioSegment
import io
import tempfile
import os
#import onnxruntime as ort

def is_audio_file(content_type: str, filename: str, file_content: bytes) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∞—É–¥–∏–æ"""
    if content_type and content_type.startswith('audio/'):
        return True

    audio_extensions = {'.wav', '.mp3', '.m4a', '.flac', '.ogg', '.aac', '.wma'}
    file_extension = '.' + filename.split('.')[-1].lower() if '.' in filename else ''
    if file_extension in audio_extensions:
        return True
    
    if not content_type and file_extension in audio_extensions:
        return True
    return False

def convert_audio_to_wav(audio_data: bytes, filename: str) -> bytes:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –≤ WAV —Ñ–æ—Ä–º–∞—Ç (16kHz, mono)"""
    try:
        file_extension = filename.split('.')[-1].lower()
        
        audio_buffer = io.BytesIO(audio_data)
        audio = AudioSegment.from_file(audio_buffer, format=file_extension)
        
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        audio = audio.set_channels(1)  # mono
        audio = audio.set_frame_rate(16000)  # 16kHz
        audio = audio.set_sample_width(2)  # 16-bit

        output_buffer = io.BytesIO()
        audio.export(output_buffer, format="wav")
        
        return output_buffer.getvalue()  
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {str(e)}")

def load_audio_from_bytes(audio_data: bytes, filename: str = None) -> np.ndarray:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ bytes –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç numpy –º–∞—Å—Å–∏–≤"""
    try:
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
            temp_file.write(audio_data)
            temp_file_path = temp_file.name

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é librosa
        audio, sr = librosa.load(temp_file_path, sr=16000, mono=True)
        
        print(f"üìä –ê—É–¥–∏–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(audio)} samples, {len(audio)/sr:.2f} —Å–µ–∫—É–Ω–¥, SR: {sr}Hz")
        
        return audio
        
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ: {str(e)}")
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

class AudioPreprocessor:
    """–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–π NeMo"""
    
    def __init__(self):
        self.sample_rate = 16000
        self.n_fft = 512
        self.win_length = 400
        self.hop_length = 160
        self.n_mels = 80
        self.window = 'hann'
        self.f_min = 0
        self.f_max = 8000
        self.dither = 1e-05
        self.preemph = 0.97
        self.log_zero_guard_value = 2**-24
        
    def compute_mel_spectrogram(self, audio):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã"""
        # –ü—Ä–µ-—ç–º—Ñ–∞–∑–∞
        audio = np.append(audio[0], audio[1:] - self.preemph * audio[:-1])
        
        # STFT
        stft = librosa.stft(
            audio,
            n_fft=self.n_fft,
            hop_length=self.hop_length,
            win_length=self.win_length,
            window=self.window,
            center=True
        )
        
        # –ê–º–ø–ª–∏—Ç—É–¥–Ω—ã–π —Å–ø–µ–∫—Ç—Ä
        magnitude = np.abs(stft)
        
        # Mel-—Ñ–∏–ª—å—Ç—Ä—ã
        mel_basis = librosa.filters.mel(
            sr=self.sample_rate,
            n_fft=self.n_fft,
            n_mels=self.n_mels,
            fmin=self.f_min,
            fmax=self.f_max,
            norm='slaney'
        )
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Mel-—Ñ–∏–ª—å—Ç—Ä–æ–≤
        mel_spectrogram = np.dot(mel_basis, magnitude)
        
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ
        log_mel = np.log(np.clip(mel_spectrogram, a_min=self.log_zero_guard_value, a_max=None))
        
        return log_mel
    
    def normalize_batch(self, features, seq_len):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        mean = features.mean(axis=2, keepdims=True)
        std = features.std(axis=2, keepdims=True)
        normalized = (features - mean) / (std + 1e-5)
        return normalized, seq_len
    
    def __call__(self, audio_signal, audio_length):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞"""
        audio_signal = np.array(audio_signal, dtype=np.float32)
        
        batch_size = audio_signal.shape[0]
        features_list = []
        features_lengths = []
        
        for i in range(batch_size):
            audio = audio_signal[i]
            length = audio_length[i]
            audio = audio[:length]
            
            mel_spec = self.compute_mel_spectrogram(audio)
            features_list.append(mel_spec)
            features_lengths.append(mel_spec.shape[1])
        
        # –°–æ–±–∏—Ä–∞–µ–º –±–∞—Ç—á
        max_length = max(features_lengths)
        batch_features = np.zeros((batch_size, self.n_mels, max_length), dtype=np.float32)
        
        for i, feat in enumerate(features_list):
            batch_features[i, :, :feat.shape[1]] = feat
        
        features_lengths = np.array(features_lengths, dtype=np.int64)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        batch_features, features_lengths = self.normalize_batch(batch_features, features_lengths)
        
        return batch_features, features_lengths

def save_input_data_for_go(audio_signal, length, filename="go_input_data.json"):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ Go (—Ç–æ—á–Ω–∞—è –∫–æ–ø–∏—è –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–æ–¥–∞)"""
    
    input_data = {
        "audio_signal": {
            "data": audio_signal.flatten().tolist(),
            "shape": list(audio_signal.shape),
            "dtype": str(audio_signal.dtype)
        },
        "length": {
            "data": length.flatten().tolist(),
            "shape": list(length.shape),
            "dtype": str(length.dtype)
        }
    }
    
    with open(filename, 'w') as f:
        json.dump(input_data, f, indent=2)
    
    print(f"üíæ –î–∞–Ω–Ω—ã–µ –¥–ª—è Go —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filename}")
    print(f"üìä Audio signal shape: {audio_signal.shape}")
    print(f"üìä Length: {length}")
    
    # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∏–Ω–∞—Ä–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    audio_signal.astype(np.float32).tofile('audio_signal.bin')
    length.astype(np.float32).tofile('length.bin')
    
    print("üíæ –ë–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: audio_signal.bin, length.bin")

def process_audio_file_for_onnx(audio_data: bytes, filename: str, content_type: str = None, model_path: str = None) -> tuple:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ –¥–ª—è ONNX –º–æ–¥–µ–ª–∏
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (input_dict, audio_info)
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —è–≤–ª—è–µ—Ç—Å—è –∞—É–¥–∏–æ
    if not is_audio_file(content_type, filename, audio_data):
        raise ValueError(f"–§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∞—É–¥–∏–æ: {filename}, content-type: {content_type}")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if not filename.lower().endswith('.wav'):
        print(f"üîß –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º {filename} –≤ WAV...")
        audio_data = convert_audio_to_wav(audio_data, filename)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –∫–∞–∫ numpy –º–∞—Å—Å–∏–≤
    audio_array = load_audio_from_bytes(audio_data, filename)
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    audio_batch = np.expand_dims(audio_array, axis=0).astype(np.float32)
    audio_length = np.array([audio_batch.shape[1]], dtype=np.int64)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    preprocessor = AudioPreprocessor()
    processed_audio, processed_audio_length = preprocessor(audio_batch, audio_length)
    
    print(f"üìä Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞: {processed_audio.shape}")

    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ö–æ–¥–∞—Ö –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤
    if model_path and os.path.exists(model_path):
        model = ort.InferenceSession(model_path)
        model_inputs = model.get_inputs()
        
        input_dict = {}
        for input_info in model_inputs:
            if input_info.name == 'audio_signal':
                input_dict[input_info.name] = processed_audio.astype(np.float32)
            elif input_info.name == 'length':
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ float –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç float
                if 'float' in input_info.type:
                    input_dict[input_info.name] = processed_audio_length.astype(np.float32)
                else:
                    input_dict[input_info.name] = processed_audio_length.astype(np.int64)
            else:
                input_dict[input_info.name] = processed_audio.astype(np.float32)
        
        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print("–¢–∏–ø—ã –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏:")
        for input_name, input_data in input_dict.items():
            print(f"  {input_name}: {input_data.dtype}, shape: {input_data.shape}")
    else:
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–∏–ø—ã
        input_dict = {
            'audio_signal': processed_audio.astype(np.float32),
            'length': processed_audio_length.astype(np.float32)  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é float
        }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è Go
    save_input_data_for_go(
        input_dict['audio_signal'], 
        input_dict['length']
    )
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞—É–¥–∏–æ
    audio_info = {
        'original_filename': filename,
        'content_type': content_type,
        'audio_samples': len(audio_array),
        'duration_seconds': len(audio_array) / 16000,
        'features_shape': processed_audio.shape,
        'features_length': int(processed_audio_length[0])
    }
    
    return input_dict, audio_info

def load_audio_file(file_path: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª —Å –¥–∏—Å–∫–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç bytes"""
    try:
        with open(file_path, 'rb') as f:
            audio_data = f.read()
        print(f"üìÅ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {file_path} ({len(audio_data)} bytes)")
        return audio_data
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º
if __name__ == "__main__":
    # –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –≤–∞—à–µ–º—É —Ä–µ–∞–ª—å–Ω–æ–º—É –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
    audio_file_path = "audio.wav"  # –∏–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ –ø—É—Ç—å –∫ –≤–∞—à–µ–º—É —Ñ–∞–π–ª—É
    
    if not os.path.exists(audio_file_path):
        print(f"‚ùå –§–∞–π–ª {audio_file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª...")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        sample_rate = 16000
        duration = 3.0
        t = np.linspace(0, duration, int(sample_rate * duration))
        audio_signal = np.sin(2 * np.pi * 440 * t)  # —Ç–æ–Ω 440 –ì—Ü
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ WAV —Ñ–∞–π–ª
        audio_segment = AudioSegment(
            (audio_signal * 32767).astype(np.int16).tobytes(),
            frame_rate=sample_rate,
            sample_width=2,  # 16-bit
            channels=1
        )
        audio_segment.export(audio_file_path, format="wav")
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {audio_file_path}")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª
        audio_data = load_audio_file(audio_file_path)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
        input_dict, audio_info = process_audio_file_for_onnx(
            audio_data=audio_data,
            filename=os.path.basename(audio_file_path),
            content_type="audio/wav",
            model_path="model_fixed.onnx" if os.path.exists("model_fixed.onnx") else None
        )
        
        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        print(f"–í—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ: {audio_info['audio_samples']} samples, {audio_info['duration_seconds']:.2f}s")
        print(f"–í—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∏—á–∏: {audio_info['features_shape']}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if os.path.exists("go_input_data.json"):
            with open("go_input_data.json", "r", encoding="utf-8") as f:
                saved_data = json.load(f)
            
            print(f"\nüíæ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞:")
            print(f"Audio signal shape: {saved_data['audio_signal']['shape']}")
            print(f"Length: {saved_data['length']['data']}")
            print(f"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö: audio_signal={saved_data['audio_signal']['dtype']}, length={saved_data['length']['dtype']}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            print(f"\nüîç –ü–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–µ–Ω–∏–π audio_signal:")
            print(saved_data['audio_signal']['data'][:5])
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            print(f"\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):")
            print(json.dumps(saved_data, indent=2)[:200] + "...")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
